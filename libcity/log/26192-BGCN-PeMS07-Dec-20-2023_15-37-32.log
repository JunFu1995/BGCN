2023-12-20 15:37:32,849 - INFO - Log directory: ./libcity/log
2023-12-20 15:37:32,849 - INFO - Begin pipeline, task=traffic_state_pred, model_name=BGCN, dataset_name=PeMS07, exp_id=26192
2023-12-20 15:37:32,849 - INFO - {'task': 'traffic_state_pred', 'model': 'BGCN', 'dataset': 'PeMS07', 'saved_model': True, 'train': True, 'seed': 0, 'dataset_class': 'TrafficStatePointDataset', 'executor': 'TrafficStateExecutor', 'evaluator': 'TrafficStateEvaluator', 'dropout': 0.3, 'blocks': 4, 'layers': 2, 'apt_layer': True, 'gcn_bool': True, 'addaptadj': True, 'adjtype': 'doubletransition', 'bidir_adj_mx': False, 'randomadj': True, 'aptonly': True, 'kernel_size': 2, 'nhid': 32, 'residual_channels': 32, 'dilation_channels': 32, 'skip_channels': 256, 'end_channels': 512, 'scaler': 'standard', 'load_external': False, 'normal_external': False, 'ext_scaler': 'none', 'add_time_in_day': False, 'add_day_in_week': False, 'max_epoch': 100, 'learner': 'adam', 'learning_rate': 0.001, 'lr_decay': False, 'clip_grad_norm': True, 'max_grad_norm': 5, 'use_early_stop': False, 'batch_size': 64, 'cache_dataset': True, 'num_workers': 0, 'pad_with_last_sample': True, 'train_rate': 0.6, 'eval_rate': 0.2, 'input_window': 12, 'output_window': 12, 'gpu': True, 'gpu_id': 0, 'train_loss': 'none', 'epoch': 0, 'weight_decay': 0, 'lr_epsilon': 1e-08, 'lr_beta1': 0.9, 'lr_beta2': 0.999, 'lr_alpha': 0.99, 'lr_momentum': 0, 'lr_scheduler': 'multisteplr', 'lr_decay_ratio': 0.1, 'steps': [5, 20, 40, 70], 'step_size': 10, 'lr_T_max': 30, 'lr_eta_min': 0, 'lr_patience': 10, 'lr_threshold': 0.0001, 'patience': 50, 'log_level': 'INFO', 'log_every': 1, 'load_best_epoch': True, 'hyper_tune': False, 'metrics': ['MAE', 'MAPE', 'MSE', 'RMSE', 'masked_MAE', 'masked_MAPE', 'masked_MSE', 'masked_RMSE', 'R2', 'EVAR'], 'evaluator_mode': 'single', 'save_mode': ['csv'], 'geo': {'including_types': ['Point'], 'Point': {}}, 'rel': {'including_types': ['geo'], 'geo': {'cost': 'num'}}, 'dyna': {'including_types': ['state'], 'state': {'entity_id': 'geo_id', 'traffic_flow': 'num'}}, 'data_col': ['traffic_flow'], 'weight_col': 'cost', 'data_files': ['PeMS07'], 'geo_file': 'PeMS07', 'rel_file': 'PeMS07', 'output_dim': 1, 'time_intervals': 300, 'init_weight_inf_or_zero': 'zero', 'set_weight_link_or_dist': 'link', 'calculate_weight_adj': False, 'weight_adj_epsilon': 0.1, 'device': device(type='cuda', index=0), 'exp_id': 26192}
2023-12-20 15:37:32,852 - INFO - Loaded file PeMS07.geo, num_nodes=883
2023-12-20 15:37:32,853 - INFO - set_weight_link_or_dist: link
2023-12-20 15:37:32,853 - INFO - init_weight_inf_or_zero: zero
2023-12-20 15:37:32,854 - INFO - Loaded file PeMS07.rel, shape=(883, 883)
2023-12-20 15:37:32,854 - INFO - Loading file PeMS07.dyna
2023-12-20 15:37:38,381 - INFO - Loaded file PeMS07.dyna, shape=(28224, 883, 1)
2023-12-20 15:37:40,527 - INFO - Dataset created
2023-12-20 15:37:40,527 - INFO - x shape: (28201, 12, 883, 1), y shape: (28201, 12, 883, 1)
2023-12-20 15:37:40,533 - INFO - train	x: (16921, 12, 883, 1), y: (16921, 12, 883, 1)
2023-12-20 15:37:40,533 - INFO - eval	x: (5640, 12, 883, 1), y: (5640, 12, 883, 1)
2023-12-20 15:37:40,533 - INFO - test	x: (5640, 12, 883, 1), y: (5640, 12, 883, 1)
2023-12-20 15:40:04,715 - INFO - Saved at ./libcity/cache/dataset_cache/point_based_PeMS07_12_12_0.6_0.2_standard_64_False_False_False_True.npz
2023-12-20 15:40:05,078 - INFO - StandardScaler mean: 309.5414726371829, std: 189.50746108430616
2023-12-20 15:40:05,078 - INFO - NoneScaler
2023-12-20 15:40:07,005 - INFO - receptive_field: 13
2023-12-20 15:40:07,116 - INFO - BGCN(
  (filter_convs): ModuleList(
    (0): Conv2d(32, 32, kernel_size=(1, 2), stride=(1, 1))
    (1): Conv2d(32, 32, kernel_size=(1, 2), stride=(1, 1), dilation=(2, 2))
    (2): Conv2d(32, 32, kernel_size=(1, 2), stride=(1, 1))
    (3): Conv2d(32, 32, kernel_size=(1, 2), stride=(1, 1), dilation=(2, 2))
    (4): Conv2d(32, 32, kernel_size=(1, 2), stride=(1, 1))
    (5): Conv2d(32, 32, kernel_size=(1, 2), stride=(1, 1), dilation=(2, 2))
    (6): Conv2d(32, 32, kernel_size=(1, 2), stride=(1, 1))
    (7): Conv2d(32, 32, kernel_size=(1, 2), stride=(1, 1), dilation=(2, 2))
  )
  (gate_convs): ModuleList(
    (0): Conv2d(32, 32, kernel_size=(1, 2), stride=(1, 1))
    (1): Conv2d(32, 32, kernel_size=(1, 2), stride=(1, 1), dilation=(2, 2))
    (2): Conv2d(32, 32, kernel_size=(1, 2), stride=(1, 1))
    (3): Conv2d(32, 32, kernel_size=(1, 2), stride=(1, 1), dilation=(2, 2))
    (4): Conv2d(32, 32, kernel_size=(1, 2), stride=(1, 1))
    (5): Conv2d(32, 32, kernel_size=(1, 2), stride=(1, 1), dilation=(2, 2))
    (6): Conv2d(32, 32, kernel_size=(1, 2), stride=(1, 1))
    (7): Conv2d(32, 32, kernel_size=(1, 2), stride=(1, 1), dilation=(2, 2))
  )
  (residual_convs): ModuleList(
    (0-7): 8 x Conv1d(32, 32, kernel_size=(1, 1), stride=(1,))
  )
  (skip_convs): ModuleList(
    (0-7): 8 x Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1))
  )
  (bn): ModuleList(
    (0-7): 8 x BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (gconv): ModuleList(
    (0-7): 8 x GCN(
      (nconv): NConv()
      (mlp): Linear(
        (mlp): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
      )
    )
  )
  (start_conv): Conv2d(1, 32, kernel_size=(1, 1), stride=(1, 1))
  (end_conv_1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))
  (end_conv_2): Conv2d(512, 12, kernel_size=(1, 1), stride=(1, 1))
)
2023-12-20 15:40:07,116 - INFO - PA	torch.Size([883, 883])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - filter_convs.0.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - filter_convs.0.bias	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - filter_convs.1.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - filter_convs.1.bias	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - filter_convs.2.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - filter_convs.2.bias	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - filter_convs.3.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - filter_convs.3.bias	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - filter_convs.4.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - filter_convs.4.bias	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - filter_convs.5.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - filter_convs.5.bias	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - filter_convs.6.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - filter_convs.6.bias	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - filter_convs.7.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - filter_convs.7.bias	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - gate_convs.0.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - gate_convs.0.bias	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - gate_convs.1.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - gate_convs.1.bias	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - gate_convs.2.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - gate_convs.2.bias	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - gate_convs.3.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - gate_convs.3.bias	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - gate_convs.4.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - gate_convs.4.bias	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - gate_convs.5.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - gate_convs.5.bias	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - gate_convs.6.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - gate_convs.6.bias	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - gate_convs.7.weight	torch.Size([32, 32, 1, 2])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - gate_convs.7.bias	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - residual_convs.0.weight	torch.Size([32, 32, 1, 1])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - residual_convs.0.bias	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - residual_convs.1.weight	torch.Size([32, 32, 1, 1])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - residual_convs.1.bias	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - residual_convs.2.weight	torch.Size([32, 32, 1, 1])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - residual_convs.2.bias	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - residual_convs.3.weight	torch.Size([32, 32, 1, 1])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - residual_convs.3.bias	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - residual_convs.4.weight	torch.Size([32, 32, 1, 1])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - residual_convs.4.bias	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - residual_convs.5.weight	torch.Size([32, 32, 1, 1])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - residual_convs.5.bias	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - residual_convs.6.weight	torch.Size([32, 32, 1, 1])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - residual_convs.6.bias	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - residual_convs.7.weight	torch.Size([32, 32, 1, 1])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - residual_convs.7.bias	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - skip_convs.0.weight	torch.Size([256, 32, 1, 1])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - skip_convs.0.bias	torch.Size([256])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - skip_convs.1.weight	torch.Size([256, 32, 1, 1])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - skip_convs.1.bias	torch.Size([256])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - skip_convs.2.weight	torch.Size([256, 32, 1, 1])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - skip_convs.2.bias	torch.Size([256])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - skip_convs.3.weight	torch.Size([256, 32, 1, 1])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - skip_convs.3.bias	torch.Size([256])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - skip_convs.4.weight	torch.Size([256, 32, 1, 1])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - skip_convs.4.bias	torch.Size([256])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - skip_convs.5.weight	torch.Size([256, 32, 1, 1])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - skip_convs.5.bias	torch.Size([256])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - skip_convs.6.weight	torch.Size([256, 32, 1, 1])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - skip_convs.6.bias	torch.Size([256])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - skip_convs.7.weight	torch.Size([256, 32, 1, 1])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - skip_convs.7.bias	torch.Size([256])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - bn.0.weight	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - bn.0.bias	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - bn.1.weight	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - bn.1.bias	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,117 - INFO - bn.2.weight	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,118 - INFO - bn.2.bias	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,118 - INFO - bn.3.weight	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,118 - INFO - bn.3.bias	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,118 - INFO - bn.4.weight	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,118 - INFO - bn.4.bias	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,118 - INFO - bn.5.weight	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,118 - INFO - bn.5.bias	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,118 - INFO - bn.6.weight	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,118 - INFO - bn.6.bias	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,118 - INFO - bn.7.weight	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,118 - INFO - bn.7.bias	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,118 - INFO - gconv.0.mlp.mlp.weight	torch.Size([32, 32, 1, 1])	cuda:0	True
2023-12-20 15:40:07,118 - INFO - gconv.0.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,118 - INFO - gconv.1.mlp.mlp.weight	torch.Size([32, 32, 1, 1])	cuda:0	True
2023-12-20 15:40:07,118 - INFO - gconv.1.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,118 - INFO - gconv.2.mlp.mlp.weight	torch.Size([32, 32, 1, 1])	cuda:0	True
2023-12-20 15:40:07,118 - INFO - gconv.2.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,118 - INFO - gconv.3.mlp.mlp.weight	torch.Size([32, 32, 1, 1])	cuda:0	True
2023-12-20 15:40:07,118 - INFO - gconv.3.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,118 - INFO - gconv.4.mlp.mlp.weight	torch.Size([32, 32, 1, 1])	cuda:0	True
2023-12-20 15:40:07,118 - INFO - gconv.4.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,118 - INFO - gconv.5.mlp.mlp.weight	torch.Size([32, 32, 1, 1])	cuda:0	True
2023-12-20 15:40:07,118 - INFO - gconv.5.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,118 - INFO - gconv.6.mlp.mlp.weight	torch.Size([32, 32, 1, 1])	cuda:0	True
2023-12-20 15:40:07,118 - INFO - gconv.6.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,118 - INFO - gconv.7.mlp.mlp.weight	torch.Size([32, 32, 1, 1])	cuda:0	True
2023-12-20 15:40:07,118 - INFO - gconv.7.mlp.mlp.bias	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,118 - INFO - start_conv.weight	torch.Size([32, 1, 1, 1])	cuda:0	True
2023-12-20 15:40:07,118 - INFO - start_conv.bias	torch.Size([32])	cuda:0	True
2023-12-20 15:40:07,118 - INFO - end_conv_1.weight	torch.Size([512, 256, 1, 1])	cuda:0	True
2023-12-20 15:40:07,118 - INFO - end_conv_1.bias	torch.Size([512])	cuda:0	True
2023-12-20 15:40:07,118 - INFO - end_conv_2.weight	torch.Size([12, 512, 1, 1])	cuda:0	True
2023-12-20 15:40:07,118 - INFO - end_conv_2.bias	torch.Size([12])	cuda:0	True
2023-12-20 15:40:07,118 - INFO - Total parameter numbers: 1035765
2023-12-20 15:40:07,118 - INFO - You select `adam` optimizer.
2023-12-20 15:40:07,118 - WARNING - Received none train loss func and will use the loss func defined in the model.
2023-12-20 15:40:07,118 - INFO - Start training ...
2023-12-20 15:40:07,118 - INFO - num_batches:265
2023-12-20 15:41:26,899 - INFO - epoch complete!
2023-12-20 15:41:26,899 - INFO - evaluating now!
2023-12-20 15:41:41,995 - INFO - Epoch [0/100] train_loss: 36.1205, val_loss: 26.6378, lr: 0.001000, 94.88s
2023-12-20 15:41:42,011 - INFO - Saved model at 0
2023-12-20 15:41:42,011 - INFO - Val loss decrease from inf to 26.6378, saving to ./libcity/cache/26192/model_cache/BGCN_PeMS07_epoch0.tar
2023-12-20 15:43:01,529 - INFO - epoch complete!
2023-12-20 15:43:01,529 - INFO - evaluating now!
2023-12-20 15:43:16,634 - INFO - Epoch [1/100] train_loss: 26.4680, val_loss: 23.6749, lr: 0.001000, 94.62s
2023-12-20 15:43:16,650 - INFO - Saved model at 1
2023-12-20 15:43:16,650 - INFO - Val loss decrease from 26.6378 to 23.6749, saving to ./libcity/cache/26192/model_cache/BGCN_PeMS07_epoch1.tar
2023-12-20 15:44:36,137 - INFO - epoch complete!
2023-12-20 15:44:36,137 - INFO - evaluating now!
2023-12-20 15:44:51,234 - INFO - Epoch [2/100] train_loss: 24.4611, val_loss: 23.4708, lr: 0.001000, 94.58s
2023-12-20 15:44:51,250 - INFO - Saved model at 2
2023-12-20 15:44:51,250 - INFO - Val loss decrease from 23.6749 to 23.4708, saving to ./libcity/cache/26192/model_cache/BGCN_PeMS07_epoch2.tar
2023-12-20 15:46:10,801 - INFO - epoch complete!
2023-12-20 15:46:10,801 - INFO - evaluating now!
2023-12-20 15:46:25,902 - INFO - Epoch [3/100] train_loss: 23.8202, val_loss: 24.5134, lr: 0.001000, 94.65s
2023-12-20 15:47:45,409 - INFO - epoch complete!
2023-12-20 15:47:45,409 - INFO - evaluating now!
2023-12-20 15:48:00,504 - INFO - Epoch [4/100] train_loss: 23.0614, val_loss: 22.9011, lr: 0.001000, 94.60s
2023-12-20 15:48:00,521 - INFO - Saved model at 4
2023-12-20 15:48:00,521 - INFO - Val loss decrease from 23.4708 to 22.9011, saving to ./libcity/cache/26192/model_cache/BGCN_PeMS07_epoch4.tar
2023-12-20 15:49:20,029 - INFO - epoch complete!
2023-12-20 15:49:20,029 - INFO - evaluating now!
2023-12-20 15:49:35,144 - INFO - Epoch [5/100] train_loss: 22.5525, val_loss: 23.0865, lr: 0.001000, 94.62s
2023-12-20 15:50:54,724 - INFO - epoch complete!
2023-12-20 15:50:54,724 - INFO - evaluating now!
2023-12-20 15:51:09,832 - INFO - Epoch [6/100] train_loss: 22.2553, val_loss: 22.3557, lr: 0.001000, 94.69s
2023-12-20 15:51:09,849 - INFO - Saved model at 6
2023-12-20 15:51:09,849 - INFO - Val loss decrease from 22.9011 to 22.3557, saving to ./libcity/cache/26192/model_cache/BGCN_PeMS07_epoch6.tar
2023-12-20 15:52:29,465 - INFO - epoch complete!
2023-12-20 15:52:29,465 - INFO - evaluating now!
2023-12-20 15:52:44,572 - INFO - Epoch [7/100] train_loss: 22.0043, val_loss: 22.1230, lr: 0.001000, 94.72s
2023-12-20 15:52:44,588 - INFO - Saved model at 7
2023-12-20 15:52:44,589 - INFO - Val loss decrease from 22.3557 to 22.1230, saving to ./libcity/cache/26192/model_cache/BGCN_PeMS07_epoch7.tar
2023-12-20 15:54:04,142 - INFO - epoch complete!
2023-12-20 15:54:04,142 - INFO - evaluating now!
2023-12-20 15:54:19,229 - INFO - Epoch [8/100] train_loss: 21.7146, val_loss: 21.7492, lr: 0.001000, 94.64s
2023-12-20 15:54:19,245 - INFO - Saved model at 8
2023-12-20 15:54:19,245 - INFO - Val loss decrease from 22.1230 to 21.7492, saving to ./libcity/cache/26192/model_cache/BGCN_PeMS07_epoch8.tar
2023-12-20 15:55:38,769 - INFO - epoch complete!
2023-12-20 15:55:38,769 - INFO - evaluating now!
2023-12-20 15:55:53,870 - INFO - Epoch [9/100] train_loss: 21.6743, val_loss: 21.8268, lr: 0.001000, 94.62s
2023-12-20 15:57:13,332 - INFO - epoch complete!
2023-12-20 15:57:13,332 - INFO - evaluating now!
2023-12-20 15:57:28,439 - INFO - Epoch [10/100] train_loss: 21.5014, val_loss: 21.6875, lr: 0.001000, 94.57s
2023-12-20 15:57:28,457 - INFO - Saved model at 10
2023-12-20 15:57:28,457 - INFO - Val loss decrease from 21.7492 to 21.6875, saving to ./libcity/cache/26192/model_cache/BGCN_PeMS07_epoch10.tar
2023-12-20 15:58:48,027 - INFO - epoch complete!
2023-12-20 15:58:48,027 - INFO - evaluating now!
2023-12-20 15:59:03,172 - INFO - Epoch [11/100] train_loss: 21.3382, val_loss: 21.3449, lr: 0.001000, 94.71s
2023-12-20 15:59:03,189 - INFO - Saved model at 11
2023-12-20 15:59:03,189 - INFO - Val loss decrease from 21.6875 to 21.3449, saving to ./libcity/cache/26192/model_cache/BGCN_PeMS07_epoch11.tar
2023-12-20 16:00:22,836 - INFO - epoch complete!
2023-12-20 16:00:22,836 - INFO - evaluating now!
2023-12-20 16:00:37,931 - INFO - Epoch [12/100] train_loss: 21.2510, val_loss: 22.1735, lr: 0.001000, 94.74s
2023-12-20 16:01:57,512 - INFO - epoch complete!
2023-12-20 16:01:57,512 - INFO - evaluating now!
2023-12-20 16:02:12,634 - INFO - Epoch [13/100] train_loss: 21.1035, val_loss: 21.5105, lr: 0.001000, 94.70s
2023-12-20 16:03:32,252 - INFO - epoch complete!
2023-12-20 16:03:32,252 - INFO - evaluating now!
2023-12-20 16:03:47,342 - INFO - Epoch [14/100] train_loss: 21.0072, val_loss: 21.5554, lr: 0.001000, 94.71s
2023-12-20 16:05:06,889 - INFO - epoch complete!
2023-12-20 16:05:06,889 - INFO - evaluating now!
2023-12-20 16:05:21,995 - INFO - Epoch [15/100] train_loss: 20.9891, val_loss: 20.9236, lr: 0.001000, 94.65s
2023-12-20 16:05:22,010 - INFO - Saved model at 15
2023-12-20 16:05:22,010 - INFO - Val loss decrease from 21.3449 to 20.9236, saving to ./libcity/cache/26192/model_cache/BGCN_PeMS07_epoch15.tar
2023-12-20 16:06:41,523 - INFO - epoch complete!
2023-12-20 16:06:41,523 - INFO - evaluating now!
2023-12-20 16:06:56,593 - INFO - Epoch [16/100] train_loss: 20.8561, val_loss: 20.9742, lr: 0.001000, 94.58s
2023-12-20 16:08:16,157 - INFO - epoch complete!
2023-12-20 16:08:16,157 - INFO - evaluating now!
2023-12-20 16:08:31,281 - INFO - Epoch [17/100] train_loss: 20.8056, val_loss: 21.2276, lr: 0.001000, 94.69s
2023-12-20 16:09:50,817 - INFO - epoch complete!
2023-12-20 16:09:50,817 - INFO - evaluating now!
2023-12-20 16:10:05,945 - INFO - Epoch [18/100] train_loss: 20.6633, val_loss: 21.2029, lr: 0.001000, 94.66s
2023-12-20 16:11:25,483 - INFO - epoch complete!
2023-12-20 16:11:25,484 - INFO - evaluating now!
2023-12-20 16:11:40,582 - INFO - Epoch [19/100] train_loss: 20.7066, val_loss: 21.2595, lr: 0.001000, 94.64s
2023-12-20 16:13:00,117 - INFO - epoch complete!
2023-12-20 16:13:00,118 - INFO - evaluating now!
2023-12-20 16:13:15,215 - INFO - Epoch [20/100] train_loss: 20.6297, val_loss: 21.1546, lr: 0.001000, 94.63s
2023-12-20 16:14:34,753 - INFO - epoch complete!
2023-12-20 16:14:34,753 - INFO - evaluating now!
2023-12-20 16:14:49,798 - INFO - Epoch [21/100] train_loss: 20.4617, val_loss: 21.0095, lr: 0.001000, 94.58s
2023-12-20 16:16:09,220 - INFO - epoch complete!
2023-12-20 16:16:09,220 - INFO - evaluating now!
2023-12-20 16:16:24,299 - INFO - Epoch [22/100] train_loss: 20.5243, val_loss: 21.3183, lr: 0.001000, 94.50s
2023-12-20 16:17:43,808 - INFO - epoch complete!
2023-12-20 16:17:43,808 - INFO - evaluating now!
2023-12-20 16:17:58,953 - INFO - Epoch [23/100] train_loss: 20.4396, val_loss: 20.9220, lr: 0.001000, 94.65s
2023-12-20 16:17:58,970 - INFO - Saved model at 23
2023-12-20 16:17:58,970 - INFO - Val loss decrease from 20.9236 to 20.9220, saving to ./libcity/cache/26192/model_cache/BGCN_PeMS07_epoch23.tar
2023-12-20 16:19:18,603 - INFO - epoch complete!
2023-12-20 16:19:18,603 - INFO - evaluating now!
2023-12-20 16:19:33,704 - INFO - Epoch [24/100] train_loss: 20.4011, val_loss: 21.1492, lr: 0.001000, 94.73s
2023-12-20 16:20:53,336 - INFO - epoch complete!
2023-12-20 16:20:53,336 - INFO - evaluating now!
2023-12-20 16:21:08,456 - INFO - Epoch [25/100] train_loss: 20.3689, val_loss: 20.7626, lr: 0.001000, 94.75s
2023-12-20 16:21:08,473 - INFO - Saved model at 25
2023-12-20 16:21:08,473 - INFO - Val loss decrease from 20.9220 to 20.7626, saving to ./libcity/cache/26192/model_cache/BGCN_PeMS07_epoch25.tar
2023-12-20 16:22:28,141 - INFO - epoch complete!
2023-12-20 16:22:28,141 - INFO - evaluating now!
2023-12-20 16:22:43,257 - INFO - Epoch [26/100] train_loss: 20.2254, val_loss: 20.9321, lr: 0.001000, 94.78s
2023-12-20 16:24:02,860 - INFO - epoch complete!
2023-12-20 16:24:02,860 - INFO - evaluating now!
2023-12-20 16:24:17,968 - INFO - Epoch [27/100] train_loss: 20.2406, val_loss: 20.9411, lr: 0.001000, 94.71s
2023-12-20 16:25:37,498 - INFO - epoch complete!
2023-12-20 16:25:37,499 - INFO - evaluating now!
2023-12-20 16:25:52,609 - INFO - Epoch [28/100] train_loss: 20.1565, val_loss: 20.6114, lr: 0.001000, 94.64s
2023-12-20 16:25:52,625 - INFO - Saved model at 28
2023-12-20 16:25:52,625 - INFO - Val loss decrease from 20.7626 to 20.6114, saving to ./libcity/cache/26192/model_cache/BGCN_PeMS07_epoch28.tar
2023-12-20 16:27:12,172 - INFO - epoch complete!
2023-12-20 16:27:12,172 - INFO - evaluating now!
2023-12-20 16:27:27,269 - INFO - Epoch [29/100] train_loss: 20.1268, val_loss: 20.5995, lr: 0.001000, 94.64s
2023-12-20 16:27:27,285 - INFO - Saved model at 29
2023-12-20 16:27:27,285 - INFO - Val loss decrease from 20.6114 to 20.5995, saving to ./libcity/cache/26192/model_cache/BGCN_PeMS07_epoch29.tar
2023-12-20 16:28:46,809 - INFO - epoch complete!
2023-12-20 16:28:46,809 - INFO - evaluating now!
2023-12-20 16:29:01,925 - INFO - Epoch [30/100] train_loss: 20.1236, val_loss: 20.7019, lr: 0.001000, 94.64s
2023-12-20 16:30:21,387 - INFO - epoch complete!
2023-12-20 16:30:21,387 - INFO - evaluating now!
2023-12-20 16:30:36,464 - INFO - Epoch [31/100] train_loss: 20.0747, val_loss: 20.7199, lr: 0.001000, 94.54s
2023-12-20 16:31:55,916 - INFO - epoch complete!
2023-12-20 16:31:55,916 - INFO - evaluating now!
2023-12-20 16:32:11,019 - INFO - Epoch [32/100] train_loss: 20.0467, val_loss: 20.7488, lr: 0.001000, 94.55s
2023-12-20 16:33:30,538 - INFO - epoch complete!
2023-12-20 16:33:30,538 - INFO - evaluating now!
2023-12-20 16:33:45,658 - INFO - Epoch [33/100] train_loss: 20.0010, val_loss: 20.8753, lr: 0.001000, 94.64s
2023-12-20 16:35:05,263 - INFO - epoch complete!
2023-12-20 16:35:05,263 - INFO - evaluating now!
2023-12-20 16:35:20,365 - INFO - Epoch [34/100] train_loss: 19.9582, val_loss: 20.9810, lr: 0.001000, 94.71s
2023-12-20 16:36:39,979 - INFO - epoch complete!
2023-12-20 16:36:39,979 - INFO - evaluating now!
2023-12-20 16:36:55,107 - INFO - Epoch [35/100] train_loss: 19.9579, val_loss: 20.5146, lr: 0.001000, 94.74s
2023-12-20 16:36:55,124 - INFO - Saved model at 35
2023-12-20 16:36:55,124 - INFO - Val loss decrease from 20.5995 to 20.5146, saving to ./libcity/cache/26192/model_cache/BGCN_PeMS07_epoch35.tar
2023-12-20 16:38:14,738 - INFO - epoch complete!
2023-12-20 16:38:14,738 - INFO - evaluating now!
2023-12-20 16:38:29,871 - INFO - Epoch [36/100] train_loss: 19.9436, val_loss: 21.2587, lr: 0.001000, 94.75s
2023-12-20 16:39:49,461 - INFO - epoch complete!
2023-12-20 16:39:49,461 - INFO - evaluating now!
2023-12-20 16:40:04,567 - INFO - Epoch [37/100] train_loss: 19.8569, val_loss: 20.5624, lr: 0.001000, 94.70s
2023-12-20 16:41:24,128 - INFO - epoch complete!
2023-12-20 16:41:24,128 - INFO - evaluating now!
2023-12-20 16:41:39,194 - INFO - Epoch [38/100] train_loss: 19.8858, val_loss: 20.5680, lr: 0.001000, 94.63s
2023-12-20 16:42:58,684 - INFO - epoch complete!
2023-12-20 16:42:58,685 - INFO - evaluating now!
2023-12-20 16:43:13,815 - INFO - Epoch [39/100] train_loss: 19.8494, val_loss: 20.7348, lr: 0.001000, 94.62s
2023-12-20 16:44:33,432 - INFO - epoch complete!
2023-12-20 16:44:33,432 - INFO - evaluating now!
2023-12-20 16:44:48,569 - INFO - Epoch [40/100] train_loss: 19.7952, val_loss: 20.5158, lr: 0.001000, 94.75s
2023-12-20 16:46:08,241 - INFO - epoch complete!
2023-12-20 16:46:08,241 - INFO - evaluating now!
2023-12-20 16:46:23,389 - INFO - Epoch [41/100] train_loss: 19.7881, val_loss: 20.9811, lr: 0.001000, 94.82s
2023-12-20 16:47:43,007 - INFO - epoch complete!
2023-12-20 16:47:43,007 - INFO - evaluating now!
2023-12-20 16:47:58,127 - INFO - Epoch [42/100] train_loss: 19.7361, val_loss: 20.5138, lr: 0.001000, 94.74s
2023-12-20 16:47:58,143 - INFO - Saved model at 42
2023-12-20 16:47:58,143 - INFO - Val loss decrease from 20.5146 to 20.5138, saving to ./libcity/cache/26192/model_cache/BGCN_PeMS07_epoch42.tar
2023-12-20 16:49:17,777 - INFO - epoch complete!
2023-12-20 16:49:17,777 - INFO - evaluating now!
2023-12-20 16:49:32,893 - INFO - Epoch [43/100] train_loss: 19.7865, val_loss: 20.6658, lr: 0.001000, 94.75s
2023-12-20 16:50:52,415 - INFO - epoch complete!
2023-12-20 16:50:52,415 - INFO - evaluating now!
2023-12-20 16:51:07,493 - INFO - Epoch [44/100] train_loss: 19.7137, val_loss: 20.5014, lr: 0.001000, 94.60s
2023-12-20 16:51:07,509 - INFO - Saved model at 44
2023-12-20 16:51:07,509 - INFO - Val loss decrease from 20.5138 to 20.5014, saving to ./libcity/cache/26192/model_cache/BGCN_PeMS07_epoch44.tar
2023-12-20 16:52:27,006 - INFO - epoch complete!
2023-12-20 16:52:27,006 - INFO - evaluating now!
2023-12-20 16:52:42,072 - INFO - Epoch [45/100] train_loss: 19.6410, val_loss: 20.7354, lr: 0.001000, 94.56s
2023-12-20 16:54:01,546 - INFO - epoch complete!
2023-12-20 16:54:01,547 - INFO - evaluating now!
2023-12-20 16:54:16,618 - INFO - Epoch [46/100] train_loss: 19.6249, val_loss: 20.3280, lr: 0.001000, 94.55s
2023-12-20 16:54:16,634 - INFO - Saved model at 46
2023-12-20 16:54:16,634 - INFO - Val loss decrease from 20.5014 to 20.3280, saving to ./libcity/cache/26192/model_cache/BGCN_PeMS07_epoch46.tar
2023-12-20 16:55:36,098 - INFO - epoch complete!
2023-12-20 16:55:36,098 - INFO - evaluating now!
2023-12-20 16:55:51,264 - INFO - Epoch [47/100] train_loss: 19.6512, val_loss: 20.5309, lr: 0.001000, 94.63s
2023-12-20 16:57:10,858 - INFO - epoch complete!
2023-12-20 16:57:10,859 - INFO - evaluating now!
2023-12-20 16:57:25,975 - INFO - Epoch [48/100] train_loss: 19.6189, val_loss: 20.5573, lr: 0.001000, 94.71s
2023-12-20 16:58:45,535 - INFO - epoch complete!
2023-12-20 16:58:45,535 - INFO - evaluating now!
2023-12-20 16:59:00,677 - INFO - Epoch [49/100] train_loss: 19.5464, val_loss: 20.4274, lr: 0.001000, 94.70s
2023-12-20 17:00:20,256 - INFO - epoch complete!
2023-12-20 17:00:20,256 - INFO - evaluating now!
2023-12-20 17:00:35,357 - INFO - Epoch [50/100] train_loss: 19.5491, val_loss: 20.4001, lr: 0.001000, 94.68s
2023-12-20 17:01:54,811 - INFO - epoch complete!
2023-12-20 17:01:54,811 - INFO - evaluating now!
2023-12-20 17:02:09,863 - INFO - Epoch [51/100] train_loss: 19.5380, val_loss: 20.5765, lr: 0.001000, 94.51s
2023-12-20 17:03:29,290 - INFO - epoch complete!
2023-12-20 17:03:29,290 - INFO - evaluating now!
2023-12-20 17:03:44,364 - INFO - Epoch [52/100] train_loss: 19.4990, val_loss: 20.4874, lr: 0.001000, 94.50s
2023-12-20 17:05:03,867 - INFO - epoch complete!
2023-12-20 17:05:03,867 - INFO - evaluating now!
2023-12-20 17:05:18,962 - INFO - Epoch [53/100] train_loss: 19.5152, val_loss: 20.4491, lr: 0.001000, 94.60s
2023-12-20 17:06:38,446 - INFO - epoch complete!
2023-12-20 17:06:38,446 - INFO - evaluating now!
2023-12-20 17:06:53,528 - INFO - Epoch [54/100] train_loss: 19.4841, val_loss: 20.5320, lr: 0.001000, 94.57s
2023-12-20 17:08:12,977 - INFO - epoch complete!
2023-12-20 17:08:12,977 - INFO - evaluating now!
2023-12-20 17:08:28,061 - INFO - Epoch [55/100] train_loss: 19.4821, val_loss: 20.5755, lr: 0.001000, 94.53s
2023-12-20 17:09:47,509 - INFO - epoch complete!
2023-12-20 17:09:47,509 - INFO - evaluating now!
2023-12-20 17:10:02,603 - INFO - Epoch [56/100] train_loss: 19.4618, val_loss: 20.4813, lr: 0.001000, 94.54s
2023-12-20 17:11:22,125 - INFO - epoch complete!
2023-12-20 17:11:22,125 - INFO - evaluating now!
2023-12-20 17:11:37,185 - INFO - Epoch [57/100] train_loss: 19.4747, val_loss: 20.4747, lr: 0.001000, 94.58s
2023-12-20 17:12:56,698 - INFO - epoch complete!
2023-12-20 17:12:56,698 - INFO - evaluating now!
2023-12-20 17:13:11,801 - INFO - Epoch [58/100] train_loss: 19.4326, val_loss: 20.8638, lr: 0.001000, 94.62s
2023-12-20 17:14:31,237 - INFO - epoch complete!
2023-12-20 17:14:31,237 - INFO - evaluating now!
2023-12-20 17:14:46,290 - INFO - Epoch [59/100] train_loss: 19.4634, val_loss: 20.3228, lr: 0.001000, 94.49s
2023-12-20 17:14:46,306 - INFO - Saved model at 59
2023-12-20 17:14:46,306 - INFO - Val loss decrease from 20.3280 to 20.3228, saving to ./libcity/cache/26192/model_cache/BGCN_PeMS07_epoch59.tar
2023-12-20 17:16:05,825 - INFO - epoch complete!
2023-12-20 17:16:05,825 - INFO - evaluating now!
2023-12-20 17:16:20,934 - INFO - Epoch [60/100] train_loss: 19.3741, val_loss: 20.8118, lr: 0.001000, 94.63s
2023-12-20 17:17:40,394 - INFO - epoch complete!
2023-12-20 17:17:40,394 - INFO - evaluating now!
2023-12-20 17:17:55,434 - INFO - Epoch [61/100] train_loss: 19.3793, val_loss: 20.5184, lr: 0.001000, 94.50s
2023-12-20 17:19:14,825 - INFO - epoch complete!
2023-12-20 17:19:14,825 - INFO - evaluating now!
2023-12-20 17:19:29,867 - INFO - Epoch [62/100] train_loss: 19.3699, val_loss: 20.1912, lr: 0.001000, 94.43s
2023-12-20 17:19:29,883 - INFO - Saved model at 62
2023-12-20 17:19:29,883 - INFO - Val loss decrease from 20.3228 to 20.1912, saving to ./libcity/cache/26192/model_cache/BGCN_PeMS07_epoch62.tar
2023-12-20 17:20:49,324 - INFO - epoch complete!
2023-12-20 17:20:49,324 - INFO - evaluating now!
2023-12-20 17:21:04,418 - INFO - Epoch [63/100] train_loss: 19.3526, val_loss: 20.6991, lr: 0.001000, 94.53s
2023-12-20 17:22:23,851 - INFO - epoch complete!
2023-12-20 17:22:23,851 - INFO - evaluating now!
2023-12-20 17:22:38,899 - INFO - Epoch [64/100] train_loss: 19.3185, val_loss: 20.2451, lr: 0.001000, 94.48s
2023-12-20 17:23:58,255 - INFO - epoch complete!
2023-12-20 17:23:58,255 - INFO - evaluating now!
2023-12-20 17:24:13,317 - INFO - Epoch [65/100] train_loss: 19.2992, val_loss: 20.0799, lr: 0.001000, 94.42s
2023-12-20 17:24:13,333 - INFO - Saved model at 65
2023-12-20 17:24:13,333 - INFO - Val loss decrease from 20.1912 to 20.0799, saving to ./libcity/cache/26192/model_cache/BGCN_PeMS07_epoch65.tar
2023-12-20 17:25:32,758 - INFO - epoch complete!
2023-12-20 17:25:32,758 - INFO - evaluating now!
2023-12-20 17:25:47,811 - INFO - Epoch [66/100] train_loss: 19.3405, val_loss: 20.3587, lr: 0.001000, 94.48s
2023-12-20 17:27:07,266 - INFO - epoch complete!
2023-12-20 17:27:07,266 - INFO - evaluating now!
2023-12-20 17:27:22,317 - INFO - Epoch [67/100] train_loss: 19.2843, val_loss: 20.1586, lr: 0.001000, 94.50s
2023-12-20 17:28:41,800 - INFO - epoch complete!
2023-12-20 17:28:41,800 - INFO - evaluating now!
2023-12-20 17:28:56,877 - INFO - Epoch [68/100] train_loss: 19.2351, val_loss: 20.1778, lr: 0.001000, 94.56s
2023-12-20 17:30:16,352 - INFO - epoch complete!
2023-12-20 17:30:16,352 - INFO - evaluating now!
2023-12-20 17:30:31,385 - INFO - Epoch [69/100] train_loss: 19.2928, val_loss: 20.3156, lr: 0.001000, 94.51s
2023-12-20 17:31:50,801 - INFO - epoch complete!
2023-12-20 17:31:50,801 - INFO - evaluating now!
2023-12-20 17:32:05,848 - INFO - Epoch [70/100] train_loss: 19.2781, val_loss: 20.1224, lr: 0.001000, 94.46s
2023-12-20 17:33:25,269 - INFO - epoch complete!
2023-12-20 17:33:25,270 - INFO - evaluating now!
2023-12-20 17:33:40,322 - INFO - Epoch [71/100] train_loss: 19.2344, val_loss: 20.3628, lr: 0.001000, 94.47s
2023-12-20 17:34:59,811 - INFO - epoch complete!
2023-12-20 17:34:59,811 - INFO - evaluating now!
2023-12-20 17:35:14,911 - INFO - Epoch [72/100] train_loss: 19.2162, val_loss: 20.0515, lr: 0.001000, 94.59s
2023-12-20 17:35:14,927 - INFO - Saved model at 72
2023-12-20 17:35:14,927 - INFO - Val loss decrease from 20.0799 to 20.0515, saving to ./libcity/cache/26192/model_cache/BGCN_PeMS07_epoch72.tar
2023-12-20 17:36:34,448 - INFO - epoch complete!
2023-12-20 17:36:34,448 - INFO - evaluating now!
2023-12-20 17:36:49,513 - INFO - Epoch [73/100] train_loss: 19.2020, val_loss: 20.1287, lr: 0.001000, 94.59s
2023-12-20 17:38:08,968 - INFO - epoch complete!
2023-12-20 17:38:08,968 - INFO - evaluating now!
2023-12-20 17:38:24,038 - INFO - Epoch [74/100] train_loss: 19.1872, val_loss: 20.2798, lr: 0.001000, 94.52s
2023-12-20 17:39:43,525 - INFO - epoch complete!
2023-12-20 17:39:43,525 - INFO - evaluating now!
2023-12-20 17:39:58,591 - INFO - Epoch [75/100] train_loss: 19.1804, val_loss: 20.1327, lr: 0.001000, 94.55s
2023-12-20 17:41:18,011 - INFO - epoch complete!
2023-12-20 17:41:18,011 - INFO - evaluating now!
2023-12-20 17:41:33,089 - INFO - Epoch [76/100] train_loss: 19.1790, val_loss: 20.2949, lr: 0.001000, 94.50s
2023-12-20 17:42:52,567 - INFO - epoch complete!
2023-12-20 17:42:52,567 - INFO - evaluating now!
2023-12-20 17:43:07,650 - INFO - Epoch [77/100] train_loss: 19.1849, val_loss: 20.0173, lr: 0.001000, 94.56s
2023-12-20 17:43:07,666 - INFO - Saved model at 77
2023-12-20 17:43:07,666 - INFO - Val loss decrease from 20.0515 to 20.0173, saving to ./libcity/cache/26192/model_cache/BGCN_PeMS07_epoch77.tar
2023-12-20 17:44:27,126 - INFO - epoch complete!
2023-12-20 17:44:27,126 - INFO - evaluating now!
2023-12-20 17:44:42,195 - INFO - Epoch [78/100] train_loss: 19.1456, val_loss: 20.3196, lr: 0.001000, 94.53s
2023-12-20 17:46:01,555 - INFO - epoch complete!
2023-12-20 17:46:01,555 - INFO - evaluating now!
2023-12-20 17:46:16,607 - INFO - Epoch [79/100] train_loss: 19.1177, val_loss: 20.1818, lr: 0.001000, 94.41s
2023-12-20 17:47:36,013 - INFO - epoch complete!
2023-12-20 17:47:36,014 - INFO - evaluating now!
2023-12-20 17:47:51,070 - INFO - Epoch [80/100] train_loss: 19.1199, val_loss: 20.4780, lr: 0.001000, 94.46s
2023-12-20 17:49:10,476 - INFO - epoch complete!
2023-12-20 17:49:10,476 - INFO - evaluating now!
2023-12-20 17:49:25,535 - INFO - Epoch [81/100] train_loss: 19.1852, val_loss: 20.2979, lr: 0.001000, 94.46s
2023-12-20 17:50:45,043 - INFO - epoch complete!
2023-12-20 17:50:45,043 - INFO - evaluating now!
2023-12-20 17:51:00,158 - INFO - Epoch [82/100] train_loss: 19.1303, val_loss: 20.0705, lr: 0.001000, 94.62s
2023-12-20 17:52:19,626 - INFO - epoch complete!
2023-12-20 17:52:19,626 - INFO - evaluating now!
2023-12-20 17:52:34,706 - INFO - Epoch [83/100] train_loss: 19.1311, val_loss: 20.0179, lr: 0.001000, 94.55s
2023-12-20 17:53:54,191 - INFO - epoch complete!
2023-12-20 17:53:54,191 - INFO - evaluating now!
2023-12-20 17:54:09,300 - INFO - Epoch [84/100] train_loss: 19.0984, val_loss: 20.2939, lr: 0.001000, 94.59s
2023-12-20 17:55:28,859 - INFO - epoch complete!
2023-12-20 17:55:28,859 - INFO - evaluating now!
2023-12-20 17:55:43,961 - INFO - Epoch [85/100] train_loss: 19.0985, val_loss: 19.9789, lr: 0.001000, 94.66s
2023-12-20 17:55:43,978 - INFO - Saved model at 85
2023-12-20 17:55:43,978 - INFO - Val loss decrease from 20.0173 to 19.9789, saving to ./libcity/cache/26192/model_cache/BGCN_PeMS07_epoch85.tar
2023-12-20 17:57:03,474 - INFO - epoch complete!
2023-12-20 17:57:03,474 - INFO - evaluating now!
2023-12-20 17:57:18,574 - INFO - Epoch [86/100] train_loss: 19.0669, val_loss: 20.3196, lr: 0.001000, 94.60s
2023-12-20 17:58:38,087 - INFO - epoch complete!
2023-12-20 17:58:38,087 - INFO - evaluating now!
2023-12-20 17:58:53,165 - INFO - Epoch [87/100] train_loss: 19.0748, val_loss: 20.3002, lr: 0.001000, 94.59s
2023-12-20 18:00:12,654 - INFO - epoch complete!
2023-12-20 18:00:12,654 - INFO - evaluating now!
2023-12-20 18:00:27,705 - INFO - Epoch [88/100] train_loss: 19.0612, val_loss: 20.0103, lr: 0.001000, 94.54s
2023-12-20 18:01:47,144 - INFO - epoch complete!
2023-12-20 18:01:47,144 - INFO - evaluating now!
2023-12-20 18:02:02,232 - INFO - Epoch [89/100] train_loss: 19.0559, val_loss: 20.1662, lr: 0.001000, 94.53s
2023-12-20 18:03:21,753 - INFO - epoch complete!
2023-12-20 18:03:21,753 - INFO - evaluating now!
2023-12-20 18:03:36,866 - INFO - Epoch [90/100] train_loss: 19.0458, val_loss: 20.2789, lr: 0.001000, 94.63s
2023-12-20 18:04:56,373 - INFO - epoch complete!
2023-12-20 18:04:56,374 - INFO - evaluating now!
2023-12-20 18:05:11,424 - INFO - Epoch [91/100] train_loss: 19.0059, val_loss: 20.0973, lr: 0.001000, 94.56s
2023-12-20 18:06:30,877 - INFO - epoch complete!
2023-12-20 18:06:30,877 - INFO - evaluating now!
2023-12-20 18:06:45,946 - INFO - Epoch [92/100] train_loss: 19.0088, val_loss: 20.0027, lr: 0.001000, 94.52s
2023-12-20 18:08:05,381 - INFO - epoch complete!
2023-12-20 18:08:05,381 - INFO - evaluating now!
2023-12-20 18:08:20,426 - INFO - Epoch [93/100] train_loss: 18.9906, val_loss: 20.0251, lr: 0.001000, 94.48s
2023-12-20 18:09:39,890 - INFO - epoch complete!
2023-12-20 18:09:39,890 - INFO - evaluating now!
2023-12-20 18:09:54,990 - INFO - Epoch [94/100] train_loss: 18.9974, val_loss: 20.0074, lr: 0.001000, 94.56s
2023-12-20 18:11:14,546 - INFO - epoch complete!
2023-12-20 18:11:14,546 - INFO - evaluating now!
2023-12-20 18:11:29,639 - INFO - Epoch [95/100] train_loss: 19.0123, val_loss: 20.0175, lr: 0.001000, 94.65s
2023-12-20 18:12:49,135 - INFO - epoch complete!
2023-12-20 18:12:49,135 - INFO - evaluating now!
2023-12-20 18:13:04,230 - INFO - Epoch [96/100] train_loss: 18.9777, val_loss: 20.2634, lr: 0.001000, 94.59s
2023-12-20 18:14:23,715 - INFO - epoch complete!
2023-12-20 18:14:23,715 - INFO - evaluating now!
2023-12-20 18:14:38,813 - INFO - Epoch [97/100] train_loss: 18.9604, val_loss: 20.0672, lr: 0.001000, 94.58s
2023-12-20 18:15:58,423 - INFO - epoch complete!
2023-12-20 18:15:58,423 - INFO - evaluating now!
2023-12-20 18:16:13,519 - INFO - Epoch [98/100] train_loss: 18.9498, val_loss: 20.0033, lr: 0.001000, 94.71s
2023-12-20 18:17:32,924 - INFO - epoch complete!
2023-12-20 18:17:32,924 - INFO - evaluating now!
2023-12-20 18:17:47,984 - INFO - Epoch [99/100] train_loss: 18.9564, val_loss: 20.2436, lr: 0.001000, 94.46s
2023-12-20 18:17:47,984 - INFO - Trained totally 100 epochs, average train time is 79.513s, average eval time is 15.091s
2023-12-20 18:17:47,998 - INFO - Loaded model at 85
2023-12-20 18:17:47,998 - INFO - Saved model at ./libcity/cache/26192/model_cache/BGCN_PeMS07.m
2023-12-20 18:17:48,014 - INFO - Start evaluating ...
2023-12-20 18:18:27,671 - INFO - Note that you select the single mode to evaluate!
2023-12-20 18:18:27,672 - INFO - Evaluate result is saved at ./libcity/cache/26192/evaluate_cache/2023_12_20_18_18_27_BGCN_PeMS07.csv
2023-12-20 18:18:27,676 - INFO - 
          MAE  MAPE          MSE       RMSE  masked_MAE  masked_MAPE   masked_MSE  masked_RMSE        R2      EVAR
1   16.924772   inf   744.286743  27.281620   16.943426     0.072645   743.134094    27.260487  0.978603  0.978603
2   18.033354   inf   873.763855  29.559496   18.025549     0.075879   867.905762    29.460239  0.974888  0.974891
3   18.827650   inf   958.192688  30.954687   18.806034     0.078739   949.472656    30.813515  0.972465  0.972487
4   19.478905   inf  1028.784912  32.074677   19.444365     0.080962  1016.782227    31.887022  0.970438  0.970513
5   20.015003   inf  1094.235107  33.079224   19.975639     0.083250  1081.092651    32.879974  0.968571  0.968650
6   20.485233   inf  1149.539062  33.904854   20.442959     0.085312  1135.391968    33.695580  0.966982  0.967033
7   20.840759   inf  1191.302368  34.515247   20.795881     0.086957  1176.244019    34.296413  0.965786  0.965834
8   21.218019   inf  1243.176270  35.258705   21.168968     0.088648  1226.810181    35.025848  0.964310  0.964354
9   21.530703   inf  1276.806030  35.732422   21.482794     0.090247  1261.127441    35.512356  0.963352  0.963383
10  21.852810   inf  1320.052490  36.332527   21.799692     0.092612  1303.705444    36.106861  0.962116  0.962133
11  22.179588   inf  1355.463501  36.816620   22.116711     0.094967  1336.615723    36.559757  0.961114  0.961122
12  22.570210   inf  1401.011597  37.430088   22.509226     0.096611  1382.641968    37.183895  0.959827  0.959833
